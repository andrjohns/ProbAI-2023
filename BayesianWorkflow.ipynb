{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrjohns/colab-testing/blob/main/dummy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bayesian Workflow - Probabilistic AI School 2023\n",
        "\n",
        "## Preparation\n",
        "\n",
        "In this tutorial we will be using the [cmdstanr](https://mc-stan.org/cmdstanr/articles/cmdstanr.html) R interface to CmdStan. The installation of the R dependencies and building of CmdStan can take some time in CoLab, so we'll download some pre-built versions of these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Download the pre-built libraries and other files for the tutorial\n",
        "system(\"git clone https://github.com/andrjohns/ProbAI-2023\")\n",
        "setwd(\"ProbAI-2023\")\n",
        "\n",
        "# Unpack CmdStan\n",
        "system(\"tar -zxf cmdstan.tar.gz\")\n",
        "\n",
        "# Add the pre-built libraries to the current R session\n",
        ".libPaths(\"colab-libs\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In addition to cmdstanr, we'll be using the [bayesplot](https://mc-stan.org/bayesplot/articles/graphical-ppcs.html) package for our graphical model checking, so let's load that library as well:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "library(cmdstanr)\n",
        "library(bayesplot)\n",
        "library(ggplot2)\n",
        "set_cmdstan_path(\"cmdstan-2.32.2\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Epilepsy RCT Workflow\n",
        "### Data\n",
        "Let's load our dataset and look at the general structure:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "load(\"epilepsy.RData\")\n",
        "head(epilepsy_rct)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Model\n",
        "\n",
        "We've decided to use a Poisson Generalised Linear Model with a log-link as our initial attempt for modelling the data:\n",
        "\n",
        "$$\n",
        "y_i \\sim Poisson(\\lambda_i) \\\\\n",
        "\\lambda_i = \\exp(\\alpha + x_i^T\\beta) \\\\\n",
        "\\alpha \\sim N(0,5) \\\\\n",
        "\\beta_{1:4} \\sim N(0,1)\n",
        "$$\n",
        "\n",
        "Let's have a look at how we would specify this in Stan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "cat(readLines(\"Stan/poisson.stan\"), sep = \"\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have our model, and we've defined the data we'll need, let's structure our epilepsy observations to the right format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "epilepsy_stan <- list(\n",
        "  N = length(unique(epilepsy_rct$patient)),\n",
        "  T = length(unique(epilepsy_rct$visit)),\n",
        "  K = 4,\n",
        "  ID = epilepsy_rct$patient,\n",
        "  x = epilepsy_rct[,c(\"treatment\",\"age\",\"baseline\",\"base_x_treat\")],\n",
        "  seizures = epilepsy_rct$seizures\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we're ready to fit our model! Remember that Stan is a *compiled* language, so first we need to compile our Stan model into an executable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mod <- cmdstan_model(\"Stan/poisson.stan\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that it's compiled, we can begin the sampling process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1mmqLsb4HGh",
        "outputId": "d0075e89-7d3b-4542-bc08-5eb58c500e62",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "fit <- mod$sample(\n",
        "  data = epilepsy_stan,\n",
        "  parallel_chains = 4,\n",
        "  refresh = 0,\n",
        "  show_messages = FALSE,\n",
        "  show_exceptions = FALSE,\n",
        "  seed = 2023\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check our diagnostics to see how the sampling went. First up, do the traceplots indicate that the chains have converged?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mcmc_trace(fit$draws(\"beta\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looking good! Let's also check our R-hat statistic and effective sample sizes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "fit$summary(\"beta\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Not bad! Let's have a look at our posterior-predictive checks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "ppc_dens_overlay(y = epilepsy_stan$seizures,\n",
        "                 fit$draws(\"ypred\", format = \"draws_matrix\")[1:20,]) +\n",
        "  coord_cartesian(xlim=c(0,100))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It looks like there are some areas where our model doesn't represent our data very well, let's see what we can do about that."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random-Effects Model\n",
        "\n",
        "We'll add a random intercept for each individual, to relax the assumption of equal mean and variance in the Poisson:\n",
        "\n",
        "$$\n",
        "y_i \\sim Poisson(\\lambda_i) \\\\\n",
        "\\lambda_i = \\exp(\\alpha + x_i^T\\beta + u_i) \\\\\n",
        "\\alpha \\sim N(0,5) \\\\\n",
        "\\beta_{1:4} \\sim N(0,1) \\\\\n",
        "u_i \\sim N(0,\\sigma) \\\\\n",
        "\\sigma \\sim Cauchy^+(0,5)\n",
        "$$\n",
        "\n",
        "How does this look in our Stan model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "cat(readLines(\"Stan/poisson_ranef.stan\"), sep = \"\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's follow the same process of compiling our model and then running sampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mod_ranef <- cmdstan_model(\"Stan/poisson_ranef.stan\")\n",
        "fit_ranef <- mod_ranef$sample(\n",
        "  data = epilepsy_stan,\n",
        "  parallel_chains = 4,\n",
        "  refresh = 0,\n",
        "  show_messages = FALSE,\n",
        "  show_exceptions = FALSE,\n",
        "  seed = 2023\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How do our convergence diagnostics and effective sample sizes look?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mcmc_trace(fit_ranef$draws(\"beta\"))\n",
        "fit_ranef$summary(\"beta\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How about our fit to the data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "ppc_dens_overlay(y = epilepsy_stan$seizures,\n",
        "                 fit_ranef$draws(\"ypred\", format = \"draws_matrix\")[1:20,]) +\n",
        "  coord_cartesian(xlim=c(0,100))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Much better! Now that we have a possible model, let's look at making it a little more efficient"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Marginalisation\n",
        "\n",
        "As a first step in our marginalisation journey, let's change our normally-distributed random effect to a Gamma with equal shape and rate parameters:\n",
        "\n",
        "$$\n",
        "y_i \\sim Poisson(\\lambda_i\\theta_i) \\\\\n",
        "\\lambda_i = \\exp(\\alpha + x_i^T\\beta) \\\\\n",
        "\\alpha \\sim N(0,5) \\\\\n",
        "\\beta_{1:4} \\sim N(0,1) \\\\\n",
        "\\theta_i \\sim Gamma(\\phi,\\phi) \\\\\n",
        "\\phi \\sim Cauchy^+(0,5)\n",
        "$$\n",
        "\n",
        "Which we would represent in Stan using:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "cat(readLines(\"Stan/poisson_gamma.stan\"), sep = \"\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's fit our new model and check our posterior-predictives:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mod_gamma <- cmdstan_model(\"Stan/poisson_gamma.stan\")\n",
        "fit_gamma <- mod_gamma$sample(\n",
        "  data = epilepsy_stan,\n",
        "  parallel_chains = 4,\n",
        "  refresh = 0,\n",
        "  show_messages = FALSE,\n",
        "  show_exceptions = FALSE,\n",
        "  seed = 2023\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "ppc_dens_overlay(y = epilepsy_stan$seizures,\n",
        "                 fit_gamma$draws(\"ypred\", format = \"draws_matrix\")[1:20,]) +\n",
        "  coord_cartesian(xlim=c(0,100))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Still looking good! But what's the point? \n",
        "\n",
        "Remember that we can represent the Poisson with a Gamma-distributed random effect as a Negative-Binomial parameterised by its mean and dispersion:\n",
        "\n",
        "$$\n",
        "\\int Poisson(y | \\lambda\\theta) \\cdot Gamma(\\theta | \\phi, \\phi) d\\theta = NB(y|\\lambda, \\phi)\n",
        "$$\n",
        "\n",
        "But don't just take my word for it, let's verify this in R by comparing the numerically integrated Poisson-Gamma with the Negative-Binomial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "lambda <- 2.65\n",
        "y <- 4\n",
        "phi <- 1.5\n",
        "\n",
        "poisson_gamma_pdf <- function(theta, y, lambda, phi) {\n",
        "  exp(dpois(y, lambda * theta, log = TRUE) + dgamma(theta, shape = phi, rate = phi, log = TRUE))\n",
        "}\n",
        "\n",
        "integrate(poisson_gamma_pdf, 0, Inf, y, lambda, phi)\n",
        "dnbinom(y, mu = lambda, size = phi)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Brilliant! Let's put this into practice with Stan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "cat(readLines(\"Stan/nb.stan\"), sep = \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mod_nb <- cmdstan_model(\"Stan/nb.stan\")\n",
        "fit_nb <- mod_nb$sample(\n",
        "  data = epilepsy_stan,\n",
        "  parallel_chains = 4,\n",
        "  refresh = 0,\n",
        "  show_messages = FALSE,\n",
        "  show_exceptions = FALSE,\n",
        "  seed = 2023\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "ppc_dens_overlay(y = epilepsy_stan$seizures,\n",
        "                 fit_nb$draws(\"ypred\", format = \"draws_matrix\")[1:20,]) +\n",
        "  coord_cartesian(xlim=c(0,100))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looking good again! How are our sampling runtimes looking?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "fit_ranef$time()$total\n",
        "fit_gamma$time()$total\n",
        "fit_nb$time()$total"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Well that's a pretty impressive improvement! How much better can we do if we use the optimised GLM distributions in Stan?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "cat(readLines(\"Stan/nb_glm.stan\"), sep = \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mod_nb_glm <- cmdstan_model(\"Stan/nb_glm.stan\")\n",
        "fit_nb_glm <- mod_nb_glm$sample(\n",
        "  data = epilepsy_stan,\n",
        "  parallel_chains = 4,\n",
        "  refresh = 0,\n",
        "  show_messages = FALSE,\n",
        "  show_exceptions = FALSE,\n",
        "  seed = 2023\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "ppc_dens_overlay(y = epilepsy_stan$seizures,\n",
        "                 fit_nb_glm$draws(\"ypred\", format = \"draws_matrix\")[1:20,]) +\n",
        "  coord_cartesian(xlim=c(0,100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "fit_ranef$time()$total\n",
        "fit_gamma$time()$total\n",
        "fit_nb$time()$total\n",
        "fit_nb_glm$time()$total"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that's a nice (and scalable) improvement!\n",
        "\n",
        "### Compare Models\n",
        "\n",
        "Now that we've finished developing our models (for now), how do they differ? Why would we prefer one over the other? Let's look at our inferences for the treatment effect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "fit_ranef$summary(\"beta[1]\")\n",
        "fit_nb_glm$summary(\"beta[1]\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The more efficient sampling of the NG-GLM model resulted in less (computational) uncertainty in our estimates, a narrower posterior and greater effective sample size.\n",
        "\n",
        "We can also see this by plotting the treatment effect posterior for each model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mcmc_dens(fit_ranef$draws(\"beta[1]\")) + coord_cartesian(xlim=c(-1,0.5))\n",
        "mcmc_dens(fit_nb_glm$draws(\"beta[1]\")) + coord_cartesian(xlim=c(-1,0.5))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNugLpRwFRzPFRoR7Z9SLZO",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
